{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2>FT001 - Extracción ingresos y pasivos </h2>\r\n",
    "<p> En este apartado se trata la base de datos FT001 </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Cargamos los paquetes que vamos a necesitar\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pyreadstat\r\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Se carga el FT001 completo desde el archivo .csv\r\n",
    "FT001 = pd.read_csv('C:/Users/Miguel Angel/OneDrive - Supersalud/Supersalud/Bases_FT/BD_actualizadas/2_Mas_reciente_25082021/FT001.csv', dtype={'Nit':object, 'Año': object, 'Periodo': object, 'Fecha': object}, encoding='latin-1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Se genera una nueva columna extrayendo el mes y el año de la variable fecha\r\n",
    "FT001['ano'] = FT001['Fecha'].str[:4]\r\n",
    "FT001['mes'] = FT001['Fecha'].str[4:6]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Se reemplazan los nombres de las columnas para facilitar el tratamiento\r\n",
    "FT001.rename(columns={'Nit': 'nit_eps', 'codigoConcepto': 'codigo','claseConcepto': 'clase'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Para hacer la suma de Valor por NIT EPS, Código del concepto, Mes y Año\r\n",
    "FT001 = FT001.groupby(['nit_eps', 'codigo', 'ano', 'mes']).agg({'valor': 'sum'}).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Se transforman las variables a STR para mejorar su manipulación\r\n",
    "FT001[['codigo']] = FT001[['codigo']].astype(float).astype(int).astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Se genera una nueva columna con la cuenta del numero de componentes que tiene el ID nitproveedor\r\n",
    "FT001['Lcod'] = FT001.codigo.str.len()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Se limpia la clasificación por Tipo de deudor\r\n",
    "FT001['tipo']= 'NA' # Se crea la columna con categoria UPC como base\r\n",
    "\r\n",
    "# Se establecen las condiciones para establecer correctamente el UPC\r\n",
    "\r\n",
    "FT001.loc[(FT001['codigo'] == \"410201\") |\r\n",
    "       (FT001['codigo'] == \"410202\") |\r\n",
    "       (FT001['codigo'] == \"410203\") |\r\n",
    "       (FT001['codigo'] == \"410207\") |\r\n",
    "       (FT001['codigo'] == \"431101\") |\r\n",
    "       (FT001['codigo'] == \"431102\") |\r\n",
    "       (FT001['codigo'] == \"431106\") |\r\n",
    "       (FT001['codigo'] == \"431122\") |\r\n",
    "       (FT001['codigo'] == \"431120\"),  \r\n",
    "       'tipo'] = 'UPC' \r\n",
    "\r\n",
    "FT001.loc[(FT001['codigo'] == '431103') | # | Regimen contributivo\r\n",
    "       (FT001['codigo'] == \"431104\") | #Regimen contributivo\r\n",
    "       (FT001['codigo'] == \"431107\") | #Regimen ubsidiado publico\r\n",
    "       (FT001['codigo'] == \"41020801\") | #410208-41020801\r\n",
    "       (FT001['codigo'] == \"410209\"),  \r\n",
    "       'tipo'] = 'CMCOP' \r\n",
    "\r\n",
    "FT001.loc[(FT001['codigo'] == '410227'),  \r\n",
    "       'tipo'] = 'PMAX' \r\n",
    "\r\n",
    "FT001.loc[(FT001['codigo'] == '410230'),  \r\n",
    "       'tipo'] = 'EnfH'\r\n",
    "\r\n",
    "FT001.loc[(FT001['codigo'] == '1105') |\r\n",
    "       (FT001['codigo'] == \"110101\") |\r\n",
    "       (FT001['codigo'] == \"110102\") |\r\n",
    "       (FT001['codigo'] == \"110103\") |\r\n",
    "       (FT001['codigo'] == \"110109\"),  \r\n",
    "       'tipo'] = 'Efectivo' "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Para hacer la suma de Valor por NIT EPS, tipo, Mes y Año\r\n",
    "FT001 = FT001.groupby(['nit_eps', 'tipo', 'mes', 'ano']).agg({'valor': 'sum'}).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Se transforman las variables a INT para mejorar su manipulación\r\n",
    "FT001[['mes', 'ano']] = FT001[['mes', 'ano']].astype(float).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p> Desde aquí se guarda la base de datos con fechas máximas por proveedor </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Se filtra el dataframe con las observaciones que cumplen las condiciones\r\n",
    "FT001_FECHA = FT001[\r\n",
    "    (FT001['ano'] == 2021)\r\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Se tranforma el formato de las columnas del dataframe \r\n",
    "FT001_FECHA[['ano', 'mes']] = FT001_FECHA[['ano', 'mes']].astype(float).astype(int)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3065: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Se procede a eliminar los duplicados dejando el último movimiento registrado. Esto se debe ya que se busca trabajar con el último dato disponible\r\n",
    "FT001_FECHA = FT001_FECHA.sort_values(['ano', 'mes']).drop_duplicates(['nit_eps'], keep='last')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Para guardar la base de datos lista para ser tratada en formato CSV\r\n",
    "FT001_FECHA.to_excel(r'C:/Users/Miguel Angel/OneDrive - Supersalud/Supersalud/Jul 6 Pagos WEB/Pagos WEB/EPS/2021/UNION_BASES/FT001_FECHA.xlsx', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p> Hasta aquí se guarda la base de datos con fechas máximas por proveedor </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "%%time\r\n",
    "# Se crea el rango de meses necesarios en cada mes\r\n",
    "fecha_ideal=range(1, 12 + 1)\r\n",
    "# Se rellena con ceros la información para los meses faltantes\r\n",
    "FT001 = FT001.set_index('mes').groupby(['nit_eps', 'tipo', 'ano']).apply(lambda x: x.reindex(index=fecha_ideal, fill_value=0)).drop(['nit_eps', 'tipo', 'ano'], 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 574 ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Se desagrupa la información\r\n",
    "FT001 = FT001.reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Se transforman las variables a INT para mejorar su manipulación\r\n",
    "FT001[['ano']] = FT001[['ano']].astype(float).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Se encuentran las observaciones que cumplen las condiciones\r\n",
    "df_filtered = FT001[\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 1) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 2) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 3) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 4) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 5) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 6) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 7) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 8) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 9) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 10) |\r\n",
    "    (FT001['ano'] == 2019) & (FT001['mes'] == 11)\r\n",
    "    ].index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Se eliminan las observaciones que cumplen las condiciones anteriore\r\n",
    "FT001 = FT001.drop(df_filtered)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Importante modificar la ultima línea del siguiente código \"fecha_ideal\" ya que aquí se define el rango en el cual se quieren tener las observaciones, en este caso está programado desde diciembre de 2019 hasta agosto de 2021. </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Se completan los años y los meses para las observaciones que no presentaron ninguna observación en un año de interés. Por ejemplo, a aquellos sujetos que reportaron cifras en 2019, pero no en 2020, se les completa el año 2020 para poder calcular la diferencia entre diciembre de 2019 y enero de 2020\r\n",
    "# Se convierte la variable en mes y año\r\n",
    "FT001[['ano', 'mes']] = FT001[['ano', 'mes']].astype(float)\r\n",
    "FT001['periodo'] = pd.to_datetime(FT001.ano*10000 + FT001.mes*100 + 1, format='%Y%m%d')\r\n",
    "fecha_ideal = pd.date_range('12-01-2019','8-01-2021',freq='M')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Se agrupa la información según NIT EPS, tipo y periodo sumando el valor de CXC que corresponda a cada agrupación descrita\r\n",
    "FT001 = FT001.groupby(['nit_eps', 'tipo', pd.Grouper(key='periodo', freq='M')])[['valor']].sum().reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Se prepara el dataframe para calcular la diferencia periodo a periodo (t+1 - t) respetando la agregación anterior\r\n",
    "FT001 = FT001.set_index('periodo').groupby(['nit_eps', 'tipo']).apply(lambda x: x.reindex(index=fecha_ideal, fill_value=0)).drop(['nit_eps', 'tipo'], 1).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Se reemplazan los nombres de las columnas para facilitar el tratamiento\r\n",
    "FT001.rename(columns={'level_2': 'periodo'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p> Desde aquí se filtra la base por la fecha máxima de reporte de la información </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Se seleccionan las columnas requeridas antes del cruce para filtrar la información (se excluye el valor de CXC)\r\n",
    "# FT001_FECHA = FT001_FECHA[['nit_eps', 'tipo', 'mes', 'ano']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# FT001.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Se modifican los nombres de las columnas para posterimente pegar las bases de datos\r\n",
    "# FT001_FECHA.rename(columns={'mes': 'ULTIMO_MES_FT001', 'ano': 'ULTIMO_ANO_FT001'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# # Se unen las dos bases de datos para obtener la información de FT004_FT003_FT005 y prestadores\r\n",
    "# FT001 = pd.merge(FT001, FT001_FECHA, how='left', left_on=['nit_eps', 'tipo'], right_on=['nit_eps', 'tipo'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# #  Se extrae el mes y el año para porterior left join con el agregado\r\n",
    "# FT001['ano'] = FT001['periodo'].dt.year\r\n",
    "# FT001['mes'] = FT001['periodo'].dt.month\r\n",
    "\r\n",
    "# #Se transforman las variables a INT para mejorar su manipulación\r\n",
    "# FT001[['ano', 'mes']] = FT001[['ano', 'mes']].astype(int)\r\n",
    "\r\n",
    "# # Se eliminan las columnas que no son de interés\r\n",
    "# FT001 = FT001.drop(['periodo'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Se crea una variable de control para filtrar por fecha del reporte\r\n",
    "# FT001['periodo'] = pd.to_datetime(FT001.ano*10000 + FT001.mes*100 + 1, format='%Y%m%d')\r\n",
    "# FT001['periodo_filtro'] = pd.to_datetime(FT001.ULTIMO_ANO_FT001*10000 + FT001.ULTIMO_MES_FT001*100 + 1, format='%Y%m%d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# # Se filtra el dataframe con las observaciones que cumplen las condiciones. La idea es eliminar aquellas observaciones que están por fuera de las fechas máximas de reporte de cada EPS, es decir, si una EPS reportó su información \r\n",
    "# FT001 = FT001[\r\n",
    "#     (FT001['periodo'] <= FT001['periodo_filtro'])\r\n",
    "#     ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Se establece el index (identificación) como NIT EPS, tipo y el periodo para cada observación\r\n",
    "FT001_dif = FT001.set_index(['nit_eps', 'tipo', 'periodo'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# FT001_dif.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# FT001_dif = FT001_dif[['valor']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Se calcula la diferencia mensual para conocer el valor mensual de cada cuenta ya que por defecto vienen agregadas (t+1 - t) y se llenan los espacios vacíos con ceros\r\n",
    "FT001_dif = FT001_dif.diff().fillna(0).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "#  Se extrae el mes y el año para porterior left join con el agregado\r\n",
    "FT001_dif['ano'] = FT001_dif['periodo'].dt.year\r\n",
    "FT001_dif['mes'] = FT001_dif['periodo'].dt.month\r\n",
    "\r\n",
    "FT001['ano'] = FT001['periodo'].dt.year\r\n",
    "FT001['mes'] = FT001['periodo'].dt.month\r\n",
    "\r\n",
    "#Se transforman las variables a INT para mejorar su manipulación\r\n",
    "FT001[['ano', 'mes']] = FT001[['ano', 'mes']].astype(int)\r\n",
    "FT001_dif[['ano', 'mes']] = FT001_dif[['ano', 'mes']].astype(int)\r\n",
    "\r\n",
    "# Se eliminan las columnas que no son de interés\r\n",
    "FT001 = FT001.drop(['periodo'], axis=1)\r\n",
    "FT001_dif = FT001_dif.drop(['periodo'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Se reemplazan los valores para los meses de enero\r\n",
    "FT001_dif.loc[(FT001_dif['mes']) == 1 & (FT001_dif['tipo'] != 'Efectivo')] = FT001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Se reemplazan los nombres de las columnas para facilitar el tratamiento\r\n",
    "FT001_dif.rename(columns={'valor': 'Dvalormes'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Se encuentran las observaciones que cumplen las condiciones (se eliminan las observaciones de 2019)\r\n",
    "df_filtered = FT001_dif[\r\n",
    "    (FT001_dif['ano'] == 2019)\r\n",
    "    ].index\r\n",
    "# Se eliminan las observaciones que cumplen las condiciones anteriores (se eliminan las observaciones de 2019)\r\n",
    "FT001_dif = FT001_dif.drop(df_filtered)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Para convertir el tipo como columna para la base de datos con la diferencia de un periodo\r\n",
    "FT001_dif = FT001_dif.pivot(index=['nit_eps', 'mes', 'ano'], columns='tipo', values='Dvalormes').fillna(0).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Para convertir el tipo como columna para la base de datos agregada\r\n",
    "FT001 = FT001.pivot(index=['nit_eps', 'mes', 'ano'], columns='tipo', values='valor').fillna(0).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Se eliminan las columnas que no son de interés en la base no diferenciada\r\n",
    "FT001 = FT001.drop(['CMCOP', 'EnfH', 'NA', 'PMAX', 'UPC'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Se reemplazan los nombres de las columnas para facilitar el tratamiento en la base no diferenciada\r\n",
    "FT001.rename(columns={'Efectivo': 'valorEfectivo'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Se unen las dos bases de datos para obtener la información en conjunto de la diferencia y el valor de Efectivo\r\n",
    "FT001_dif = pd.merge(FT001_dif, FT001, how='left', left_on=['nit_eps', 'ano', 'mes'], right_on=['nit_eps', 'ano', 'mes'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Se reemplazan los nombres de las columnas para facilitar el tratamiento\r\n",
    "FT001_dif.rename(columns={'Efectivo': 'DEfectivo', 'CMCOP': 'DCMCOPmes', 'PMAX': 'DPMAXmes', 'UPC': 'DUPCmes'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p> Desde aquí se filtra la base por la fecha máxima de reporte de la información </p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Se seleccionan las columnas requeridas antes del cruce para filtrar la información (se excluye el valor de CXC)\r\n",
    "FT001_FECHA = FT001_FECHA[['nit_eps', 'mes', 'ano']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "FT001_dif.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1045 entries, 0 to 1044\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   nit_eps        1045 non-null   object \n",
      " 1   mes            1045 non-null   int64  \n",
      " 2   ano            1045 non-null   int64  \n",
      " 3   DCMCOPmes      1045 non-null   float64\n",
      " 4   DEfectivo      1045 non-null   float64\n",
      " 5   EnfH           1045 non-null   float64\n",
      " 6   NA             1045 non-null   float64\n",
      " 7   DPMAXmes       1045 non-null   float64\n",
      " 8   DUPCmes        1045 non-null   float64\n",
      " 9   valorEfectivo  1045 non-null   float64\n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 89.8+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Se modifican los nombres de las columnas para posterimente pegar las bases de datos\r\n",
    "FT001_FECHA.rename(columns={'mes': 'ULTIMO_MES_FT001', 'ano': 'ULTIMO_ANO_FT001'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Se unen las dos bases de datos para obtener la información de FT004_FT003_FT005 y prestadores\r\n",
    "FT001 = pd.merge(FT001_dif, FT001_FECHA, how='left', left_on=['nit_eps'], right_on=['nit_eps'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Se crea una variable de control para filtrar por fecha del reporte\r\n",
    "FT001['periodo'] = pd.to_datetime(FT001.ano*10000 + FT001.mes*100 + 1, format='%Y%m%d')\r\n",
    "FT001['periodo_filtro'] = pd.to_datetime(FT001.ULTIMO_ANO_FT001*10000 + FT001.ULTIMO_MES_FT001*100 + 1, format='%Y%m%d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Se filtra el dataframe con las observaciones que cumplen las condiciones. La idea es eliminar aquellas observaciones que están por fuera de las fechas máximas de reporte de cada EPS, es decir, si una EPS reportó su información \r\n",
    "FT001 = FT001[\r\n",
    "    (FT001['periodo'] <= FT001['periodo_filtro'])\r\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Para guardar la base de datos lista para ser tratada en formato Excel y CSV\r\n",
    "# FT001_dif.to_excel(r'C:/Users/Miguel Angel/Documents/Supersalud/Pagos_EPS_Proveedores/ingresosyefectivo_2020_ene_may_2021.xlsx', index = False)\r\n",
    "FT001.to_csv(r'C:/Users/Miguel Angel/Documents/Supersalud/Pagos_EPS_Proveedores/ingresosyefectivo_2020_ene_jul_2021.csv', index = False, encoding='utf-8-sig')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Se eliminan la bases que no se necesitan para liberar espacio en la memoria\r\n",
    "del [FT001_dif, FT001, FT001_FECHA, df_filtered, fecha_ideal, df]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}